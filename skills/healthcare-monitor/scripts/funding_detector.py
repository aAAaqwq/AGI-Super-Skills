#!/usr/bin/env python3
"""
åŒ»ç–—ä¼ä¸šèèµ„æ£€æµ‹å™¨
ä½¿ç”¨å¤šç§å…è´¹æ•°æ®æºæ£€æµ‹èèµ„ä¿¡å·ï¼š
1. æ–°é—»æœç´¢ - 36æ°ªã€åŠ¨è„‰ç½‘ã€æŠ•èµ„ç•Œç­‰
2. å…¬å¼€å·¥å•†ä¿¡æ¯ - çˆ±ä¼æŸ¥ï¼ˆç™¾åº¦ï¼‰
3. æŠ•èèµ„æ•°æ®åº“ - ITæ¡”å­ã€çƒ¯ç‰›æ•°æ®ç­‰å…¬å¼€ä¿¡æ¯
"""

import json
import os
import re
import subprocess
import sys
from datetime import datetime, timedelta
from pathlib import Path
from urllib.parse import quote

# é…ç½®
SKILL_DIR = Path(__file__).parent.parent
CONFIG_DIR = SKILL_DIR / "config"
DATA_DIR = SKILL_DIR / "data"

# èèµ„å…³é”®è¯
FUNDING_KEYWORDS = [
    "èèµ„", "æŠ•èµ„", "è·æŠ•", "å®Œæˆèèµ„", "å®£å¸ƒèèµ„",
    "Aè½®", "Bè½®", "Cè½®", "Dè½®", "Pre-A", "å¤©ä½¿è½®", "ç§å­è½®",
    "æˆ˜ç•¥æŠ•èµ„", "è‚¡æƒèèµ„", "å¢èµ„", "å…¥è‚¡",
    "é¢†æŠ•", "è·ŸæŠ•", "ä¼°å€¼"
]

# æŠ•èµ„æœºæ„å…³é”®è¯
INVESTOR_KEYWORDS = [
    "èµ„æœ¬", "æŠ•èµ„", "åŸºé‡‘", "åˆ›æŠ•", "é£æŠ•", "VC", "PE",
    "çº¢æ‰", "é«˜ç“´", "IDG", "ç»çº¬", "å¯æ˜", "è½¯é“¶", "è…¾è®¯æŠ•èµ„",
    "é˜¿é‡Œå¥åº·", "ç™¾åº¦é£æŠ•", "å­—èŠ‚è·³åŠ¨", "ç¾å›¢é¾™ç "
]

# å™ªéŸ³å…³é”®è¯ (éœ€æ’é™¤)
NOISE_KEYWORDS = [
    "èèµ„èåˆ¸", "èèµ„ä½™é¢", "èèµ„ä¹°å…¥", "èèµ„å‡€ä¹°å…¥",
    "èèµ„å‡€å¿è¿˜", "ä¸¤è", "èèµ„å®¢", "èèµ„ç›˜",
    "æ¶¨åœ", "è·Œåœ", "è‚¡ä»·", "å¸‚å€¼è’¸å‘"
]

# æ–°é—»æº
NEWS_SOURCES = [
    {"name": "36æ°ª", "search_url": "https://36kr.com/search/articles/{query}"},
    {"name": "åŠ¨è„‰ç½‘", "search_url": "https://vcbeat.top/search?q={query}"},
    {"name": "æŠ•èµ„ç•Œ", "search_url": "https://www.pedaily.cn/search?q={query}"},
    {"name": "äº¿æ¬§", "search_url": "https://www.iyiou.com/search?q={query}"},
]


def load_companies():
    """åŠ è½½ç›‘æ§ä¼ä¸šåˆ—è¡¨"""
    with open(CONFIG_DIR / "companies.json", "r", encoding="utf-8") as f:
        return json.load(f)["companies"]


def search_news_firecrawl(company_name: str, days: int = 7) -> list:
    """
    ä½¿ç”¨ Firecrawl API æœç´¢æ–°é—»
    """
    try:
        # è·å– API key
        result = subprocess.run(
            ["pass", "show", "api/firecrawl"],
            capture_output=True, text=True
        )
        api_key = result.stdout.strip()
        
        if not api_key:
            print(f"âš ï¸ Firecrawl API key æœªé…ç½®", file=sys.stderr)
            return []
        
        # æ„å»ºæœç´¢æŸ¥è¯¢
        query = f"{company_name} èèµ„"
        
        import requests
        
        # Firecrawl search API
        response = requests.post(
            "https://api.firecrawl.dev/v1/search",
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            },
            json={
                "query": query,
                "limit": 10,
                "lang": "zh"
            },
            timeout=30
        )
        
        if response.status_code == 200:
            data = response.json()
            results = []
            for item in data.get("data", []):
                results.append({
                    "title": item.get("title", ""),
                    "url": item.get("url", ""),
                    "snippet": item.get("description", ""),
                    "source": "firecrawl"
                })
            return results
        else:
            print(f"âš ï¸ Firecrawl æœç´¢å¤±è´¥: {response.status_code}", file=sys.stderr)
            return []
            
    except Exception as e:
        print(f"âš ï¸ Firecrawl æœç´¢å¼‚å¸¸: {e}", file=sys.stderr)
        return []


def search_news_web(company_name: str) -> list:
    """
    ä½¿ç”¨ web_fetch æŠ“å–æ–°é—»
    """
    results = []
    
    # 36æ°ªæœç´¢
    try:
        import requests
        from bs4 import BeautifulSoup
        
        url = f"https://36kr.com/search/articles/{quote(company_name + ' èèµ„')}"
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        
        response = requests.get(url, headers=headers, timeout=15)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, "html.parser")
            articles = soup.select("article, .article-item, .search-result-item")[:5]
            
            for article in articles:
                title_elem = article.select_one("h3, .title, a")
                if title_elem:
                    results.append({
                        "title": title_elem.get_text(strip=True),
                        "url": title_elem.get("href", ""),
                        "source": "36æ°ª"
                    })
    except Exception as e:
        print(f"âš ï¸ 36æ°ªæœç´¢å¤±è´¥: {e}", file=sys.stderr)
    
    return results


def analyze_funding_signal(company_name: str, news_items: list) -> dict:
    """
    åˆ†æèèµ„ä¿¡å·
    """
    signals = []
    confidence = 0
    
    for item in news_items:
        title = item.get("title", "")
        snippet = item.get("snippet", "")
        text = f"{title} {snippet}"
        
        # æ£€æŸ¥å™ªéŸ³å…³é”®è¯ - æ’é™¤èèµ„èåˆ¸ç­‰
        is_noise = any(noise in text for noise in NOISE_KEYWORDS)
        if is_noise:
            continue  # è·³è¿‡å™ªéŸ³æ–°é—»
        
        # æ£€æŸ¥èèµ„å…³é”®è¯
        funding_matches = [kw for kw in FUNDING_KEYWORDS if kw in text]
        investor_matches = [kw for kw in INVESTOR_KEYWORDS if kw in text]
        
        if funding_matches:
            signal = {
                "source": item.get("source", "unknown"),
                "title": title,
                "url": item.get("url", ""),
                "keywords": funding_matches,
                "investors": investor_matches
            }
            signals.append(signal)
            
            # è®¡ç®—ç½®ä¿¡åº¦
            confidence += len(funding_matches) * 15
            confidence += len(investor_matches) * 10
            
            # æ£€æŸ¥èèµ„è½®æ¬¡
            round_match = re.search(r"(Pre-[A-Z]|[A-Z]è½®|å¤©ä½¿è½®|ç§å­è½®|æˆ˜ç•¥)", text)
            if round_match:
                signal["round"] = round_match.group(1)
                confidence += 20
            
            # æ£€æŸ¥é‡‘é¢
            amount_match = re.search(r"(\d+(?:\.\d+)?)\s*(äº¿|ä¸‡|ç¾å…ƒ|äººæ°‘å¸|å…ƒ)", text)
            if amount_match:
                signal["amount"] = f"{amount_match.group(1)}{amount_match.group(2)}"
                confidence += 15
    
    # é™åˆ¶ç½®ä¿¡åº¦æœ€å¤§å€¼
    confidence = min(confidence, 95)
    
    return {
        "company": company_name,
        "has_signal": len(signals) > 0,
        "confidence": confidence,
        "signals": signals,
        "checked_at": datetime.now().isoformat()
    }


def check_company(company: dict) -> dict:
    """
    æ£€æŸ¥å•ä¸ªä¼ä¸šçš„èèµ„ä¿¡å·
    """
    name = company["name"]
    full_name = company.get("full_name", name)
    
    print(f"ğŸ” æ£€æŸ¥: {name}", file=sys.stderr)
    
    # æœç´¢æ–°é—»
    news_items = []
    
    # 1. å°è¯• Firecrawl
    firecrawl_results = search_news_firecrawl(name)
    news_items.extend(firecrawl_results)
    
    # 2. å°è¯•ç›´æ¥æŠ“å–
    if len(news_items) < 3:
        web_results = search_news_web(name)
        news_items.extend(web_results)
    
    # åˆ†æä¿¡å·
    analysis = analyze_funding_signal(name, news_items)
    analysis["category"] = company.get("category", "æœªåˆ†ç±»")
    analysis["priority"] = company.get("priority", "normal")
    
    return analysis


def run_daily_check():
    """
    æ‰§è¡Œæ¯æ—¥æ£€æŸ¥
    """
    companies = load_companies()
    today = datetime.now().strftime("%Y-%m-%d")
    
    results = {
        "date": today,
        "total": len(companies),
        "checked": 0,
        "signals_found": 0,
        "companies": []
    }
    
    for company in companies:
        try:
            analysis = check_company(company)
            results["companies"].append(analysis)
            results["checked"] += 1
            
            if analysis["has_signal"]:
                results["signals_found"] += 1
                
        except Exception as e:
            print(f"âŒ æ£€æŸ¥ {company['name']} å¤±è´¥: {e}", file=sys.stderr)
    
    # ä¿å­˜ç»“æœ
    results_dir = DATA_DIR / "funding_checks"
    results_dir.mkdir(parents=True, exist_ok=True)
    
    results_file = results_dir / f"check_{today}.json"
    with open(results_file, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    return results


def format_telegram_report(results: dict) -> str:
    """
    æ ¼å¼åŒ– Telegram æŠ¥å‘Š
    """
    report = f"""ğŸ¥ **åŒ»ç–—ä¼ä¸šèèµ„ç›‘æ§æ—¥æŠ¥**

ğŸ“… æ—¥æœŸ: {results['date']}
ğŸ“Š ç›‘æ§ä¼ä¸š: {results['total']} å®¶
âœ… å·²æ£€æŸ¥: {results['checked']} å®¶
ğŸš¨ å‘ç°ä¿¡å·: {results['signals_found']} ä¸ª

"""
    
    # æœ‰ä¿¡å·çš„ä¼ä¸š
    signals = [c for c in results['companies'] if c['has_signal']]
    
    if signals:
        report += "**ğŸ”” èèµ„ä¿¡å·**\n\n"
        for company in signals:
            report += f"**{company['company']}** ({company['category']})\n"
            report += f"ç½®ä¿¡åº¦: {company['confidence']}%\n"
            
            for signal in company['signals'][:2]:
                report += f"â€¢ {signal['title'][:50]}...\n"
                if signal.get('round'):
                    report += f"  è½®æ¬¡: {signal['round']}\n"
                if signal.get('amount'):
                    report += f"  é‡‘é¢: {signal['amount']}\n"
            report += "\n"
    else:
        report += "**ğŸ“­ æš‚æ— èèµ„ä¿¡å·**\n\n"
    
    report += f"---\n_ç›‘æ§æ—¶é—´: {datetime.now().strftime('%H:%M')}_"
    
    return report


def push_to_telegram(message: str):
    """
    æ¨é€åˆ° Telegram
    """
    push_script = SKILL_DIR / "scripts" / ".." / ".." / "telegram-push" / "telegram-push.sh"
    if not push_script.exists():
        push_script = Path.home() / "clawd" / "skills" / "telegram-push" / "telegram-push.sh"
    
    if push_script.exists():
        subprocess.run([str(push_script), message], check=True)
        print("âœ… å·²æ¨é€åˆ° Telegram", file=sys.stderr)
    else:
        print("âš ï¸ telegram-push.sh ä¸å­˜åœ¨", file=sys.stderr)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="åŒ»ç–—ä¼ä¸šèèµ„æ£€æµ‹")
    parser.add_argument("--check", action="store_true", help="æ‰§è¡Œæ£€æŸ¥")
    parser.add_argument("--push", action="store_true", help="æ¨é€æŠ¥å‘Š")
    parser.add_argument("--company", type=str, help="æ£€æŸ¥å•ä¸ªä¼ä¸š")
    
    args = parser.parse_args()
    
    if args.company:
        # æ£€æŸ¥å•ä¸ªä¼ä¸š
        company = {"name": args.company, "full_name": args.company}
        result = check_company(company)
        print(json.dumps(result, ensure_ascii=False, indent=2))
        
    elif args.check:
        # æ‰§è¡Œæ¯æ—¥æ£€æŸ¥
        results = run_daily_check()
        
        # æ ¼å¼åŒ–æŠ¥å‘Š
        report = format_telegram_report(results)
        print(report)
        
        if args.push:
            push_to_telegram(report)
    else:
        parser.print_help()
